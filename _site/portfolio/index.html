<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Portfolio</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="Portfolio" />
<meta name="author" content="Parijat Bhatt" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/portfolio/" />
<meta property="og:url" content="http://localhost:4000/portfolio/" />
<script type="application/ld+json">
{"@type":"WebPage","headline":"Portfolio","url":"http://localhost:4000/portfolio/","author":{"@type":"Person","name":"Parijat Bhatt"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><!--  <a class="site-title" rel="author" href="/"></a> --><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          <!--<a class="page-link" href="/portfolio/">Portfolio</a>-->
	     
  <!-- <a href="/">Home</a> | -->
  <a href="/">Home</a> |
  
  <a href="/portfolio/">Portfolio</a> | 
<a href="/workExperience/">Work Ex</a> |
  <a href="/assets/resume.pdf" download>CV</a>  


	</div>
      </nav></div>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-167568658-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-167568658-1');
</script>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">

	<h2 id="course-work"><u>Course Work</u></h2>

<p>Data Structures, Algorithms, Calculus, Statistics theory, Statistical Methods, Probability,  Machine Learning, Deep Learning, Reinforcement Learning, Artificial Intelligence, Operating Systems,
Databases, Computer Architecture, Programming Languages.</p>
<h2 id="projects"><u>Projects</u></h2>

<p><strong>1.    Linear Regression for Ames Housing Dataset.</strong>  <br />
	Built an explanatory linear model for the data.  <br />
	Performed model selection using backward elimination and lasso regression. <br />
	Applied box cox tranformation while performing model checking.  <br />
	Used qqplots and residual vs fitted values plot to check for violation of assumptions.
	<a href="https://github.com/bhparijat/Hypothesis-Testing-for-Linear-Models/tree/master/Project">code link</a></p>

<p><strong>2.    Crime Data integration for different metropolitan cities.</strong>   <br />
	Collected 20 million crime records for 12 different metropolitan cities.  <br />
	Performed ETL operation to sanitize data. <br />
	Created a common SQL schema with useful attributes to build a MySQL database of 20 million arrest records.   <br />
	Performed queries on the MySQL database to generate a summary of crimes in particular cities.</p>

<p><strong>2.	Sentiment Analysis of Yelp Reviews:</strong>    <br />
	Performed data cleaning.  <br />
	Implemented a TF-IDF model using PySpark to obtain an AUROC score of 0.9.
	Created a custom dataset and dataloader using Pytorch for data cleaning and validation. <br />
	Built a neural network model that obtained a test accuracy of 93% .
	<a href="https://github.com/bhparijat/Yelp-reviews-PyTorch-and-Pyspark">Code link</a> <br />
	<u>Framework and platform used:</u> PyTorch, Apache Spark and Google Cloud Dataproc cluster for spark job, OSU HPC cluster.</p>

<p><strong>3.    Recommendation System for MovieLens Dataset</strong><br />
	Created a recommendation system for 10 million movies of MovieLens dataset by implementing collaborative filtering and matrix factorization.  <br />
	Used nearest neighbor algorithm for the collaborative filtering method and alternating least squares method for matrix factorization.  <br />
	<u>Framework and platform used:</u> Apache Spark and Google Cloud Platform. You may find the <a href="https://github.com/bhparijat/Recommendation-system">code here</a>.</p>

<p><strong>4.    NYPD Crime Data Analysis</strong><br />
	Reverse geocoded 4.8 million addresses using open source GIS database Pelias.    <br />
	Performed webscrapping to map zipcodes to city names and county names.      <br />
	Ananlysed and generated summary statistics and visualizations for the crimes happened in New York between 2014 and 2017.       <br />
	<u>Framework and platform used:</u> Google Cloud Platform, Google Maps Platform, BeautifulSoup, Pandas, Seaborn,Tableau, Pelias. <a href="https://github.com/bhparijat/NYPD-crime-analysis">Code link</a></p>

<p><strong>5.    Monte Carlo Tree Search For Atari Game Pong</strong><br />
	My teammate <a href="https://www.linkedin.com/in/sudharkj/">Ravi</a> and I, created a Monte Carlo Tree Search and deep learning model, to generate a policy for action selection for the atari game Pong.
	We implemented ideas from the famous deep-learning paper
	<a href="https://web.eecs.umich.edu/~baveja/Papers/UCTtoCNNsAtariGames-FinalVersion.pdf">Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning</a>.
	The optimal policy generated could beat random policy by a significant margin.<u>Framework and platform used:</u> PyTorch, OpenAI gym, OSU pelican cloud.
	<a href="https://github.com/bhparijat/Monte-Carlo-Tree-Search-For-Pong">Code link</a>
	<br /></p>

<p><strong>6.    Exploration Map Inpainting</strong><br />
	For the deep learning class, I alongwith my friend <a href="https://sites.google.com/view/manishsaroya/home?authuser=0">Manish Saroya</a>, worked on the
	<a href="https://www.subtchallenge.com/index.html">Darpa Subterranean Challenge</a> to develop a model that could rapidly map complex environments. We created a synthetic map database of 60K images
	consisting of grid-based maps. Our model could learn loop-closures, T-points and fill image holes. For this project, we used ideas from <a href="https://arxiv.org/abs/1804.07723">Partial Convolution Paper</a> to implement our own UNET structure for image inpainting.<u>Framework and platform used:</u> PyTorch, OSU cloud cluster. You may find a complete report on the
	<a href="https://bhparijat.github.io/assets/report.pdf">project here</a>. <a href="https://github.com/bhparijat/map-inpainting">Code link</a>
	<br /></p>

<p><strong>7.    Lottery Scheduling</strong><br />
	Implemented lottery scheduling to schedule processes in xv6 environment. Each process when created would be given a ticket. Whenever a process in the ready queue is to be scheduled, a random
	ticket is generated and tickets for the processess in the queue are summed up. As soon as the sum goes beyond the random number, a process is scheduled. <u>Framework and platform:</u> C, xv6,
	OSU server. Here is the <a href="https://github.com/bhparijat/Operating-Systems/tree/master/hw4">code link</a>.<br /></p>

<p><strong>8.    Parallel Reinforcement Learning</strong> <br />
	My teammate <a href="http://www.adhikariaashish.com.np/">Aashish</a> and I,  implemented reinforcement learning algorithms like value iteration, policy iteration, Q-learning, SARSA and Deep-Q-Network
	using <a href="https://github.com/ray-project/ray">Ray library</a> to leverage computation power of multiple CPUs. The parallel implementation significantly improved the overall computation time for
	larger environments without affecting the resultant policy. All the implementation was done on Intel Dev Cloud. The code can be found
	<a href="https://github.com/bhparijat/Parallel-Reinforcement-Learning">here</a>.<br /></p>

<p><strong>9. 	Gesture Recognition</strong> <br />
	Trained a deep neural network with softmax cross entropy loss and adam optimization for images containing hand gestures. The trained model attained an accuracy of over 91%.
	<u>Framework and platform:</u> Tensorflow and pelican cluster of Oregon State University. The jupyter notebook containing code can be found
	<a href="https://github.com/bhparijat/gesture_recognition/blob/master/sign_recognition_using__DNN.ipynb">here</a>. <br /></p>

<p><strong>10. 	Apparel Classification</strong><br />
	Trained a CNN model on Nvidia GPUs, to classify 10 types of apparel and other clothing wear. Used Adam optimizer and Cross Entropy loss for training to attain a final loss of
	0.0035. <a href="https://github.com/bhparijat/Image-classification-Fashion-MNIST/blob/master/Fashion-MNIST.ipynb">jupyter notebook link</a><br /></p>

<p><strong>11.	Web crawling</strong>     <br />
	Used BeautifulSoup library to implement a python script that could  scrape reviews of restaurants in San Francisco from Yelp website.
	<a href="https://github.com/bhparijat/web-scraping">Code link</a></p>

<h2 id="graduate-research"><u>Graduate Research</u></h2>

<p><strong>Deep Learning and Reinforcement Learning</strong> <br /></p>

<p>My advisor, <a href="http://web.engr.oregonstate.edu/~tadepall/">Prof. Prasad Tadepalli</a> and I, are working on developing an AI-player algorithm using Monte Carlo Tree Search and Graph neural networks for the game of <a href="https://www.solitaire-klondike.com/">Klondike Solitaire</a>.</p>

<!-- hitwebcounter Code START -->
<p><a href="https://www.hitwebcounter.com" target="_blank">
<img src="https://hitwebcounter.com/counter/counter.php?page=7349976&amp;style=0001&amp;nbdigits=5&amp;type=page&amp;initCount=0" title="Web Counter" alt="counter free" border="0" />
</a></p>


      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h3 class="footer-heading">Parijat Bhatt</h3> 

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <!-- <li class="p-name">Parijat Bhatt</li> --><li><a class="u-email" href="mailto:bhattpa@oregonstate.edu">bhattpa@oregonstate.edu</a></li><li><p>15419082125</p></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/bhparijat"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">bhparijat</span></a></li><li><a href="https://www.linkedin.com/in/parijatbhatt"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">parijatbhatt</span></a></li><li><a href="https://www.twitter.com/parijat_267"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">parijat_267</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p></p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
